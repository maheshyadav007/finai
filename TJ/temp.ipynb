{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587e41ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsdf\n"
     ]
    }
   ],
   "source": [
    "print(\"fsdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d079a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/3_f614jn2dl80g90y__djfgr0000gp/T/ipykernel_72132/2360824190.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/myadav503/Desktop/1 Projects/2 Personal/FinAI/TJ/sample_ohlc.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ensure file path is valid in current container\n",
    "fname = \"sample_ohlc.csv\"\n",
    "\n",
    "rows = []\n",
    "now = datetime.utcnow()\n",
    "start = now - timedelta(hours=100)\n",
    "price = 64000.0\n",
    "\n",
    "for i in range(100):\n",
    "    ts = int((start + timedelta(hours=i)).timestamp() * 1000)  # ms epoch\n",
    "    open_p = price\n",
    "    high_p = open_p + random.uniform(50, 300)\n",
    "    low_p = open_p - random.uniform(50, 300)\n",
    "    close_p = random.uniform(low_p, high_p)\n",
    "    vol = random.uniform(10, 100)\n",
    "    rows.append([ts, open_p, high_p, low_p, close_p, vol, \"BTCUSDT\"])\n",
    "    price = close_p\n",
    "\n",
    "with open(fname, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"symbol\"])\n",
    "    writer.writerows(rows)\n",
    "\n",
    "os.path.abspath(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f110cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 309 fills.\n",
      "First fill: {'commission': '0', 'created_at': '2025-08-25T20:32:41.897796Z', 'fill_type': 'normal', 'id': 'e8457e97ef4e4e649c4fe8c7101bcc66', 'meta_data': {'commission_deto': '0', 'commission_deto_in_settling_asset': '0', 'effective_commission_rate': '0.0005', 'ip': None, 'is_commission_on_notional': True, 'liquidation_fee_deto': '0', 'liquidation_fee_deto_in_settling_asset': '0', 'liquidation_fee_in_settling_asset': '0', 'mark': '188.30345198', 'new_position': {'bankruptcy_price': None, 'commission': '0.00000000000000000000', 'liquidation_price': None, 'margin': '0.00000000', 'meta_data': {'open_fills': []}, 'realized_pnl': '-3.33450000', 'size': 0}, 'order_price': '169.745', 'order_size': 5, 'order_type': 'market_order', 'order_unfilled_size': '0', 'rack_commision': '0.55544075', 'source': 'web', 'spot': '188.35666667', 'tfc_used_for_commission': '0.00', 'tfc_used_for_liquidation_fee': '-0', 'total_commission_in_settling_asset': '0', 'total_liquidation_fee_in_settling_asset': '-0'}, 'notional': '941.425', 'order_id': '875971359', 'price': '188.285', 'product': {'contract_type': 'perpetual_futures', 'contract_unit_currency': 'SOL', 'contract_value': '1', 'id': 14823, 'notional_type': 'vanilla', 'quoting_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'settling_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'spot_index': {'symbol': '.DESOLUSD'}, 'symbol': 'SOLUSD', 'tick_size': '0.0001', 'underlying_asset': {'minimum_precision': 4, 'precision': 8, 'symbol': 'SOL'}}, 'product_id': 14823, 'product_symbol': 'SOLUSD', 'role': 'taker', 'settling_asset_id': 14, 'settling_asset_symbol': 'USD', 'side': 'sell', 'size': '5'}\n",
      "Fetched 828 closed/cancelled orders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "import requests\n",
    "\n",
    "API_KEY    = 'QuNWkG8HsnHELwdcDWZgPWemINWQPJ'\n",
    "API_SECRET = 'Qbt03P2E07cH85ExjJH0mcXW45Fb49CVaNrRXoA75Bj6sEQnj6foMpUV1Npw'\n",
    "BASE_URL   = \"https://api.india.delta.exchange\"\n",
    "\n",
    "# TODO: Set these values from your own account\n",
    "# API_KEY = os.getenv(\"DELTA_API_KEY\", \"YOUR_API_KEY\")\n",
    "# API_SECRET = os.getenv(\"DELTA_API_SECRET\", \"YOUR_API_SECRET\")\n",
    "USER_AGENT = \"delta-python-script\"\n",
    "\n",
    "def generate_signature(secret: str, message: str) -> str:\n",
    "    \"\"\"Generate HMAC SHA256 signature for the given message.\"\"\"\n",
    "    return hmac.new(secret.encode(), message.encode(), hashlib.sha256).hexdigest()\n",
    "\n",
    "def call_private_api(method: str, path: str, params: dict | None = None,\n",
    "                     body: dict | None = None) -> dict:\n",
    "    \"\"\"\n",
    "    Send an authenticated request to DeltaExchange.\n",
    "    - method: HTTP method ('GET', 'POST', etc.)\n",
    "    - path: endpoint path (e.g. '/v2/fills')\n",
    "    - params: query parameters (dict)\n",
    "    - body: JSON serialisable body for non‑GET requests\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    if body is None:\n",
    "        payload = \"\"\n",
    "    else:\n",
    "        # DeltaExchange expects the body string (no spaces)\n",
    "        payload = json.dumps(body, separators=(\",\", \":\"))\n",
    "\n",
    "    # Build the query string\n",
    "    query_string = f\"?{urlencode(params, doseq=True)}\" if params else \"\"\n",
    "\n",
    "    # Timestamp in seconds (Delta requires this header within ±5 seconds):contentReference[oaicite:4]{index=4}.\n",
    "    timestamp = str(int(time.time()))\n",
    "\n",
    "    # Prepare prehash string: method + timestamp + path + query_string + payload\n",
    "    message = f\"{method}{timestamp}{path}{query_string}{payload}\"\n",
    "    signature = generate_signature(API_SECRET, message)\n",
    "\n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"signature\": signature,\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    url = BASE_URL + path\n",
    "    # For GET requests, pass payload via params; otherwise via data\n",
    "    response = requests.request(\n",
    "        method=method,\n",
    "        url=url,\n",
    "        params=params,\n",
    "        data=payload if method != \"GET\" else None,\n",
    "        headers=headers,\n",
    "        timeout=(5, 20),\n",
    "    )\n",
    "    # Raise if non‑success status (e.g. 401, 429)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def fetch_all_pages(path: str, extra_params: dict | None = None) -> list:\n",
    "    \"\"\"\n",
    "    Iterate through all pages of a paginated DeltaExchange endpoint.\n",
    "    Returns a list of all records.\n",
    "    \"\"\"\n",
    "    if extra_params is None:\n",
    "        extra_params = {}\n",
    "\n",
    "    page_size = extra_params.get(\"page_size\", 100)\n",
    "    cursor = None\n",
    "    all_records: list = []\n",
    "\n",
    "    while True:\n",
    "        params = extra_params.copy()\n",
    "        params[\"page_size\"] = page_size\n",
    "        if cursor:\n",
    "            params[\"after\"] = cursor  # use after cursor for next page:contentReference[oaicite:5]{index=5}.\n",
    "        response = call_private_api(\"GET\", path, params=params)\n",
    "        # On success, response dict contains 'result' and 'meta'\n",
    "        records = response.get(\"result\", [])\n",
    "        all_records.extend(records)\n",
    "\n",
    "        # Stop if no pagination metadata\n",
    "        meta = response.get(\"meta\", {})\n",
    "        cursor = meta.get(\"after\")\n",
    "        if not cursor:\n",
    "            break\n",
    "    return all_records\n",
    "\n",
    "def get_all_fills(start_time: int | None = None, end_time: int | None = None,\n",
    "                  product_ids: str | None = None, contract_types: str | None = None,\n",
    "                  page_size: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all fills (executions/trades) for your account.\n",
    "    - start_time/end_time: microsecond epoch timestamps to filter by time:contentReference[oaicite:6]{index=6}.\n",
    "    - product_ids: comma‑separated product IDs, optional:contentReference[oaicite:7]{index=7}.\n",
    "    - contract_types: comma‑separated contract types, optional:contentReference[oaicite:8]{index=8}.\n",
    "    \"\"\"\n",
    "    params: dict = {\"page_size\": page_size}\n",
    "    if product_ids:\n",
    "        params[\"product_ids\"] = product_ids\n",
    "    if contract_types:\n",
    "        params[\"contract_types\"] = contract_types\n",
    "    if start_time:\n",
    "        params[\"start_time\"] = start_time\n",
    "    if end_time:\n",
    "        params[\"end_time\"] = end_time\n",
    "    return fetch_all_pages(\"/v2/fills\", params)\n",
    "\n",
    "def get_all_order_history(start_time: int | None = None, end_time: int | None = None,\n",
    "                          product_ids: str | None = None, contract_types: str | None = None,\n",
    "                          order_types: str | None = None, page_size: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all closed/cancelled orders from your account:contentReference[oaicite:9]{index=9}.\n",
    "    - order_types: comma‑separated order types (e.g. 'market,limit,stop_limit'):contentReference[oaicite:10]{index=10}.\n",
    "    \"\"\"\n",
    "    params: dict = {\"page_size\": page_size}\n",
    "    if product_ids:\n",
    "        params[\"product_ids\"] = product_ids\n",
    "    if contract_types:\n",
    "        params[\"contract_types\"] = contract_types\n",
    "    if order_types:\n",
    "        params[\"order_types\"] = order_types\n",
    "    if start_time:\n",
    "        params[\"start_time\"] = start_time\n",
    "    if end_time:\n",
    "        params[\"end_time\"] = end_time\n",
    "    return fetch_all_pages(\"/v2/orders/history\", params)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: download all fills (trades) for your account\n",
    "    try:\n",
    "        fills = get_all_fills(page_size=100)\n",
    "        print(f\"Fetched {len(fills)} fills.\")\n",
    "        # Inspect the first fill\n",
    "        if fills:\n",
    "            print(\"First fill:\", fills[0])\n",
    "    except requests.HTTPError as err:\n",
    "        print(\"HTTP error:\", err)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    # Example: download all order history\n",
    "    try:\n",
    "        orders = get_all_order_history(page_size=100)\n",
    "        print(f\"Fetched {len(orders)} closed/cancelled orders.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching orders:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb89d233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'side': 'sell',\n",
       " 'created_at': '2025-08-25T20:21:32.842227Z',\n",
       " 'average_fill_price': '188.285',\n",
       " 'trail_amount': None,\n",
       " 'client_order_id': None,\n",
       " 'state': 'closed',\n",
       " 'time_in_force': 'gtc',\n",
       " 'product': {'contract_type': 'perpetual_futures',\n",
       "  'contract_unit_currency': 'SOL',\n",
       "  'contract_value': '1',\n",
       "  'id': 14823,\n",
       "  'notional_type': 'vanilla',\n",
       "  'quoting_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'},\n",
       "  'settling_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'},\n",
       "  'spot_index': {'symbol': '.DESOLUSD'},\n",
       "  'symbol': 'SOLUSD',\n",
       "  'tick_size': '0.0001',\n",
       "  'underlying_asset': {'minimum_precision': 4,\n",
       "   'precision': 8,\n",
       "   'symbol': 'SOL'}},\n",
       " 'meta_data': {'avg_exit_price': '188.285',\n",
       "  'cashflow': '-3.3345',\n",
       "  'edit_timestamp': '2025-08-25 20:21:47.987021Z',\n",
       "  'entry_price': '188.95190000',\n",
       "  'exit_price_with_size': [{'price': '188.28500000', 'size': '5'}],\n",
       "  'ip': None,\n",
       "  'otc': False,\n",
       "  'pnl': '-3.3345',\n",
       "  'roe': '-28.23575735412028140495014869',\n",
       "  'source': 'web'},\n",
       " 'id': 875971359,\n",
       " 'mmp': 'disabled',\n",
       " 'bracket_take_profit_price': None,\n",
       " 'order_type': 'market_order',\n",
       " 'unfilled_size': 0,\n",
       " 'product_id': 14823,\n",
       " 'stop_order_type': 'stop_loss_order',\n",
       " 'bracket_stop_loss_price': None,\n",
       " 'bracket_order': True,\n",
       " 'product_symbol': 'SOLUSD',\n",
       " 'reduce_only': True,\n",
       " 'user_id': 93020796,\n",
       " 'updated_at': '2025-08-25T20:32:41.954658Z',\n",
       " 'bracket_stop_loss_limit_price': None,\n",
       " 'stop_price': '188.3276',\n",
       " 'bracket_take_profit_limit_price': None,\n",
       " 'quote_size': None,\n",
       " 'bracket_trail_amount': None,\n",
       " 'stop_trigger_method': 'mark_price',\n",
       " 'cancellation_reason': None,\n",
       " 'paid_commission': '0',\n",
       " 'size': 5,\n",
       " 'close_on_trigger': 'false',\n",
       " 'commission': '0',\n",
       " 'limit_price': '169.745'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792408a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fills fetched: 511\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hmac\n",
    "import hashlib\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "import requests\n",
    "\n",
    "# Use the correct environment:\n",
    "# BASE_URL = \"https://api.india.delta.exchange\"\n",
    "\n",
    "API_KEY    = \"VJOGAFCUKX7S2XIX\"\n",
    "API_SECRET = \"Rz1miB9WrT4AOxYDAaxbAaJe2eCZAj\"\n",
    "\n",
    "API_KEY    = 'QuNWkG8HsnHELwdcDWZgPWemINWQPJ'\n",
    "API_SECRET = 'Qbt03P2E07cH85ExjJH0mcXW45Fb49CVaNrRXoA75Bj6sEQnj6foMpUV1Npw'\n",
    "\n",
    "BASE_URL   = \"https://api.india.delta.exchange\"\n",
    "USER_AGENT = \"python-3.10\"  # Delta suggests using your language version:contentReference[oaicite:6]{index=6}\n",
    "\n",
    "def generate_signature(secret, message):\n",
    "    return hmac.new(secret.encode(), message.encode(), hashlib.sha256).hexdigest()\n",
    "\n",
    "def delta_request(method, path, params=None, body=None):\n",
    "    if params is None:\n",
    "        params = {}\n",
    "    timestamp = str(int(time.time()))\n",
    "    body_str = json.dumps(body, separators=(\",\", \":\")) if body else \"\"\n",
    "    query = \"?\" + urlencode(params, doseq=True) if params else \"\"\n",
    "    message = method + timestamp + path + query + body_str\n",
    "    signature = generate_signature(API_SECRET, message)\n",
    "\n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"signature\": signature,\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    url = BASE_URL + path\n",
    "    response = requests.request(method, url, params=params, data=body_str if method != \"GET\" else None, headers=headers)\n",
    "    response.raise_for_status()  # will show 401 details if auth fails\n",
    "    return response.json()\n",
    "\n",
    "# Example: Fetch all fills (executed trades) with pagination\n",
    "def get_all_fills(page_size=100):\n",
    "    fills = []\n",
    "    cursor = None\n",
    "    while True:\n",
    "        params = {\"page_size\": page_size}\n",
    "        if cursor:\n",
    "            params[\"after\"] = cursor\n",
    "        result = delta_request(\"GET\", \"/v2/fills\", params=params)\n",
    "        fills.extend(result.get(\"result\", []))\n",
    "        cursor = result.get(\"meta\", {}).get(\"after\")\n",
    "        if not cursor:\n",
    "            break\n",
    "    return fills\n",
    "\n",
    "try:\n",
    "    all_fills = get_all_fills()\n",
    "    print(f\"Total fills fetched: {len(all_fills)}\")\n",
    "except requests.HTTPError as err:\n",
    "    print(\"HTTP error:\", err.response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8449f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commission': '0.04459265',\n",
       " 'created_at': '2025-08-25T20:21:32.681147Z',\n",
       " 'fill_type': 'normal',\n",
       " 'id': 'cde29e7eb62b48d6aa5d33eec099d675',\n",
       " 'meta_data': {'commission_deto': '0',\n",
       "  'commission_deto_in_settling_asset': '0',\n",
       "  'effective_commission_rate': '0.0002',\n",
       "  'ip': '103.111.180.131',\n",
       "  'is_commission_on_notional': True,\n",
       "  'liquidation_fee_deto': '0',\n",
       "  'liquidation_fee_deto_in_settling_asset': '0',\n",
       "  'liquidation_fee_in_settling_asset': '0',\n",
       "  'mark': '189.05251347',\n",
       "  'new_position': {'auto_topup': True,\n",
       "   'bankruptcy_price': '186.59000125',\n",
       "   'commission': '0.1115409829473000000000000000',\n",
       "   'entry_price': '188.95190000',\n",
       "   'liquidation_price': '187.53476075',\n",
       "   'margin': '2.36189875',\n",
       "   'meta_data': {'open_fills': [['buy',\n",
       "      '1',\n",
       "      '2025-08-25T20:21:32.693036Z',\n",
       "      '0.04459265',\n",
       "      '188.9519000000000000000000000']]},\n",
       "   'size': 1,\n",
       "   'total_commission_paid': '0.04459265'},\n",
       "  'order_price': '188.9519',\n",
       "  'order_size': '5',\n",
       "  'order_type': 'limit_order',\n",
       "  'order_unfilled_size': '4',\n",
       "  'rack_commision': '0.0445926484',\n",
       "  'source': 'desktop',\n",
       "  'spot': '189.10333333',\n",
       "  'tfc_used_for_commission': '0.000000000000000000',\n",
       "  'tfc_used_for_liquidation_fee': '-0',\n",
       "  'total_commission_in_settling_asset': '0.04459265',\n",
       "  'total_liquidation_fee_in_settling_asset': '-0'},\n",
       " 'notional': '188.9519',\n",
       " 'order_id': '875931602',\n",
       " 'price': '188.9519',\n",
       " 'product': {'contract_type': 'perpetual_futures',\n",
       "  'contract_unit_currency': 'SOL',\n",
       "  'contract_value': '1',\n",
       "  'id': 14823,\n",
       "  'notional_type': 'vanilla',\n",
       "  'quoting_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'},\n",
       "  'settling_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'},\n",
       "  'spot_index': {'symbol': '.DESOLUSD'},\n",
       "  'symbol': 'SOLUSD',\n",
       "  'tick_size': '0.0001',\n",
       "  'underlying_asset': {'minimum_precision': 4,\n",
       "   'precision': 8,\n",
       "   'symbol': 'SOL'}},\n",
       " 'product_id': 14823,\n",
       " 'product_symbol': 'SOLUSD',\n",
       " 'role': 'maker',\n",
       " 'settling_asset_id': 14,\n",
       " 'settling_asset_symbol': 'USD',\n",
       " 'side': 'buy',\n",
       " 'size': '1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fills[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377155b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, hmac, hashlib, json, requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "BASE_URL   = \"https://api.india.delta.exchange\"   # ← India prod, not global/testnet!\n",
    "\n",
    "def _sign(method: str, path: str, params: dict | None = None, body: dict | None = None):\n",
    "    \"\"\"\n",
    "    Signature = HMAC_SHA256(secret, method + timestamp + path + query_string + body_json)\n",
    "    - query_string must include the leading '?', and be URL-encoded\n",
    "    - body_json must be the exact JSON sent on the wire (no spaces)\n",
    "    \"\"\"\n",
    "    ts = str(int(time.time()))\n",
    "    q  = f\"?{urlencode(params, doseq=True)}\" if params else \"\"\n",
    "    b  = json.dumps(body, separators=(\",\", \":\")) if body else \"\"\n",
    "    prehash = f\"{method.upper()}{ts}{path}{q}{b}\"\n",
    "    sig = hmac.new(API_SECRET.encode(), prehash.encode(), hashlib.sha256).hexdigest()\n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"signature\": sig,\n",
    "        \"timestamp\": ts,\n",
    "        \"User-Agent\": \"python-3.12\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    return headers, b\n",
    "\n",
    "def _request(method: str, path: str, params=None, body=None):\n",
    "    headers, body_json = _sign(method, path, params, body)\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "    if method.upper() == \"GET\":\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "    elif method.upper() == \"POST\":\n",
    "        r = requests.post(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "    elif method.upper() == \"DELETE\":\n",
    "        r = requests.delete(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method\")\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "def get_all_orders(states: list[str] | None = None, page_size: int = 200):\n",
    "    \"\"\"\n",
    "    Pulls ALL orders (open/pending/cancelled) from /v2/orders using cursor pagination,\n",
    "    and ALL historical (closed/filled, etc.) from /v2/orders/history.\n",
    "    \"\"\"\n",
    "    def _page_through(path):\n",
    "        out = []\n",
    "        after = None\n",
    "        while True:\n",
    "            params = {\"page_size\": page_size}\n",
    "            if after: params[\"after\"] = after\n",
    "            if states: params[\"states\"] = \",\".join(states)\n",
    "            data = _request(\"GET\", path, params=params)\n",
    "            out.extend(data.get(\"result\", []))\n",
    "            meta = data.get(\"meta\") or {}\n",
    "            after = meta.get(\"after\")\n",
    "            if not after:\n",
    "                break\n",
    "        return out\n",
    "\n",
    "    current = _page_through(\"/v2/orders\")          # open/pending/cancelled\n",
    "    history = _page_through(\"/v2/orders/history\")  # closed/filled (historical)\n",
    "    return current + history\n",
    "\n",
    "# Example usage:\n",
    "# orders = get_all_orders(states=None)                   # everything\n",
    "# open_orders = get_all_orders(states=[\"open\",\"pending\"])\n",
    "# print(len(orders), orders[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46745e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders: 828 | Fills: 309\n",
      "{'order_id': '878398215', 'state': 'cancelled', 'product_symbol': 'SOLUSD', 'side': 'buy', 'submitted_size': 5, 'filled_size': 0.0, 'avg_fill_price': None, 'fee_total': 0.0, 'created_at': '2025-08-26T08:40:13.592281Z', 'updated_at': '2025-08-26T08:40:22.017796Z', 'order_type': 'limit_order', 'reduce_only': False, 'time_in_force': 'gtc'}\n",
      "{'order_id': '875971359', 'state': 'closed', 'product_symbol': 'SOLUSD', 'side': 'sell', 'submitted_size': 5, 'filled_size': 5.0, 'avg_fill_price': 188.285, 'fee_total': 0.0, 'created_at': '2025-08-25T20:21:32.842227Z', 'updated_at': '2025-08-25T20:32:41.954658Z', 'order_type': 'market_order', 'reduce_only': True, 'time_in_force': 'gtc'}\n",
      "{'order_id': '875931602', 'state': 'closed', 'product_symbol': 'SOLUSD', 'side': 'buy', 'submitted_size': 5, 'filled_size': 5.0, 'avg_fill_price': 188.9519, 'fee_total': 0.0, 'created_at': '2025-08-25T20:12:58.624013Z', 'updated_at': '2025-08-25T20:21:33.058646Z', 'order_type': 'limit_order', 'reduce_only': False, 'time_in_force': 'gtc'}\n"
     ]
    }
   ],
   "source": [
    "# delta_india_client.py\n",
    "# Authenticated REST client for Delta Exchange India (orders + fills)\n",
    "# Works with: https://api.india.delta.exchange\n",
    "\n",
    "import os, time, hmac, hashlib, json, requests\n",
    "from urllib.parse import urlencode\n",
    "from typing import Optional, Iterable, Dict, Any, List, Tuple\n",
    "\n",
    "# API_KEY    = os.getenv(\"DELTA_API_KEY\")    # set in your env\n",
    "# API_SECRET = os.getenv(\"DELTA_API_SECRET\") # set in your env\n",
    "BASE_URL   = \"https://api.india.delta.exchange\"\n",
    "USER_AGENT = \"delta-india-python/1.0\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from typing import Union, Optional\n",
    "\n",
    "TimeLike = Union[int, float, str, datetime]\n",
    "\n",
    "def _to_unix_seconds(t: Optional[TimeLike]) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Convert various time inputs to UNIX seconds (UTC).\n",
    "    Accepts:\n",
    "      - int/float (assumed seconds)\n",
    "      - datetime (aware = used as-is; naive = assumed UTC)\n",
    "      - ISO-8601 string (e.g., '2025-08-01', '2025-08-01T10:00:00Z')\n",
    "    Returns None if t is None.\n",
    "    \"\"\"\n",
    "    if t is None:\n",
    "        return None\n",
    "    if isinstance(t, (int, float)):\n",
    "        return int(t)\n",
    "    if isinstance(t, datetime):\n",
    "        if t.tzinfo is None:\n",
    "            t = t.replace(tzinfo=timezone.utc)\n",
    "        return int(t.timestamp())\n",
    "    if isinstance(t, str):\n",
    "        # allow date-only (interpreted as 00:00:00Z) and full ISO\n",
    "        s = t.strip()\n",
    "        if len(s) == 10 and s[4] == \"-\" and s[7] == \"-\":  # 'YYYY-MM-DD'\n",
    "            dt = datetime.fromisoformat(s).replace(tzinfo=timezone.utc)\n",
    "            return int(dt.timestamp())\n",
    "        # general ISO; tolerate trailing 'Z'\n",
    "        dt = datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return int(dt.timestamp())\n",
    "    raise TypeError(f\"Unsupported time type: {type(t)}\")\n",
    "def filter_orders_by_time(orders: list[dict], start: Optional[TimeLike] = None, end: Optional[TimeLike] = None) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Return only orders whose created_at is within [start, end] (inclusive).\n",
    "    - start/end can be UNIX seconds, datetime, or ISO-8601 strings.\n",
    "    - If only start is provided: keep orders with created_at >= start.\n",
    "    - If only end is provided: keep orders with created_at <= end.\n",
    "    \"\"\"\n",
    "    start_s = _to_unix_seconds(start)\n",
    "    end_s   = _to_unix_seconds(end)\n",
    "\n",
    "    def _created_ts(o: dict) -> Optional[int]:\n",
    "        s = o.get(\"created_at\")\n",
    "        if not s:\n",
    "            return None\n",
    "        try:\n",
    "            dt = datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "            if dt.tzinfo is None:\n",
    "                dt = dt.replace(tzinfo=timezone.utc)\n",
    "            return int(dt.timestamp())\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    out = []\n",
    "    for o in orders:\n",
    "        ts = _created_ts(o)\n",
    "        if ts is None:\n",
    "            continue\n",
    "        if start_s is not None and ts < start_s:\n",
    "            continue\n",
    "        if end_s is not None and ts > end_s:\n",
    "            continue\n",
    "        out.append(o)\n",
    "    return out\n",
    "\n",
    "class DeltaIndiaError(Exception):\n",
    "    pass\n",
    "\n",
    "def _assert_keys():\n",
    "    if not API_KEY or not API_SECRET:\n",
    "        raise DeltaIndiaError(\"Missing DELTA_API_KEY / DELTA_API_SECRET environment variables.\")\n",
    "\n",
    "def _now_ts() -> str:\n",
    "    # Delta expects seconds (int) as string\n",
    "    return str(int(time.time()))\n",
    "\n",
    "def _build_query(params: Optional[dict]) -> str:\n",
    "    if not params:\n",
    "        return \"\"\n",
    "    # NOTE: urlencode must match the exact query you send\n",
    "    return \"?\" + urlencode(params, doseq=True)\n",
    "\n",
    "def _sign(method: str, path: str, params: Optional[dict] = None, body: Optional[dict] = None) -> Tuple[dict, str]:\n",
    "    \"\"\"\n",
    "    Signature = HMAC_SHA256(secret, method + timestamp + path + query + body_json)\n",
    "    - method: GET/POST/DELETE (upper)\n",
    "    - timestamp: seconds since epoch (string)\n",
    "    - query: include leading '?' if present\n",
    "    - body_json: exact JSON string sent on the wire (minified, no spaces)\n",
    "    \"\"\"\n",
    "    _assert_keys()\n",
    "    ts = _now_ts()\n",
    "    q  = _build_query(params)\n",
    "    b  = json.dumps(body, separators=(\",\", \":\")) if body else \"\"\n",
    "    prehash = f\"{method.upper()}{ts}{path}{q}{b}\"\n",
    "    sig = hmac.new(API_SECRET.encode(), prehash.encode(), hashlib.sha256).hexdigest()\n",
    "    headers = {\n",
    "        \"api-key\": API_KEY,\n",
    "        \"signature\": sig,\n",
    "        \"timestamp\": ts,\n",
    "        \"User-Agent\": USER_AGENT,\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    return headers, b\n",
    "\n",
    "def _request(method: str, path: str, params: Optional[dict] = None, body: Optional[dict] = None) -> dict:\n",
    "    headers, body_json = _sign(method, path, params, body)\n",
    "    url = f\"{BASE_URL}{path}\"\n",
    "\n",
    "    try:\n",
    "        if method.upper() == \"GET\":\n",
    "            r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        elif method.upper() == \"POST\":\n",
    "            r = requests.post(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "        elif method.upper() == \"DELETE\":\n",
    "            r = requests.delete(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "        # Raise for HTTP errors (401, 403, 429, 5xx)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        # Delta private endpoints typically return {\"success\": bool, \"result\": [...], \"meta\": {...}} or similar\n",
    "        if isinstance(data, dict) and data.get(\"success\") is False:\n",
    "            raise DeltaIndiaError(f\"Delta API error: {data}\")\n",
    "        return data\n",
    "    except requests.HTTPError as e:\n",
    "        # Bubble up with more context\n",
    "        msg = e.response.text if e.response is not None else str(e)\n",
    "        raise DeltaIndiaError(f\"HTTPError {e.response.status_code if e.response else ''}: {msg}\") from e\n",
    "    except requests.RequestException as e:\n",
    "        raise DeltaIndiaError(f\"Network error: {e}\") from e\n",
    "\n",
    "# ---------- High-level helpers ----------\n",
    "\n",
    "def _page_through(path: str, params: Optional[dict] = None, page_size: int = 200, max_pages: Optional[int] = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generic cursor paginator for Delta India private list endpoints.\n",
    "    Loops on meta.after until exhausted (or max_pages reached).\n",
    "    \"\"\"\n",
    "    params = dict(params or {})\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    after = None\n",
    "    pages = 0\n",
    "\n",
    "    while True:\n",
    "        req_params = dict(params)\n",
    "        req_params[\"page_size\"] = page_size\n",
    "        if after:\n",
    "            req_params[\"after\"] = after\n",
    "\n",
    "        data = _request(\"GET\", path, params=req_params)\n",
    "        result = data.get(\"result\", [])\n",
    "        out.extend(result)\n",
    "\n",
    "        meta = data.get(\"meta\") or {}\n",
    "        after = meta.get(\"after\")\n",
    "        pages += 1\n",
    "\n",
    "        if not after:\n",
    "            break\n",
    "        if max_pages is not None and pages >= max_pages:\n",
    "            break\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- Orders ----------\n",
    "\n",
    "def get_all_orders(\n",
    "    states: Optional[Iterable[str]] = None,\n",
    "    product_ids: Optional[Iterable[int]] = None,\n",
    "    page_size: int = 200,\n",
    "    max_pages: Optional[int] = None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch ALL orders = open/pending/cancelled + historical closed orders.\n",
    "    - states: e.g., [\"open\",\"pending\",\"cancelled\",\"closed\"] or None for all\n",
    "    - product_ids: optional filter (list -> comma-separated)\n",
    "    \"\"\"\n",
    "    base_params = {}\n",
    "    if states:\n",
    "        base_params[\"states\"] = \",\".join(states)\n",
    "    if product_ids:\n",
    "        base_params[\"product_ids\"] = \",\".join(str(p) for p in product_ids)\n",
    "\n",
    "    current = _page_through(\"/v2/orders\", base_params, page_size, max_pages)\n",
    "    history = _page_through(\"/v2/orders/history\", base_params, page_size, max_pages)\n",
    "    return current + history\n",
    "\n",
    "# ---------- Fills ----------\n",
    "def get_all_orders_in_range(\n",
    "        start: Optional[TimeLike] = None,\n",
    "        end: Optional[TimeLike] = None,\n",
    "        **kwargs\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Fetch all orders (open + history) and filter by created_at in [start, end].\n",
    "        kwargs are passed to get_all_orders (e.g., product_ids, states, page_size).\n",
    "        \"\"\"\n",
    "        all_orders = get_all_orders(**kwargs)\n",
    "        return filter_orders_by_time(all_orders, start=start, end=end)\n",
    "def get_all_fills(\n",
    "    product_ids: Optional[Iterable[int]] = None,\n",
    "    page_size: int = 200,\n",
    "    max_pages: Optional[int] = None,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch ALL fills (executions) for your account (AUTH REQUIRED).\n",
    "    - product_ids: optional filter\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    if product_ids:\n",
    "        params[\"product_ids\"] = \",\".join(str(p) for p in product_ids)\n",
    "    return _page_through(\"/v2/fills\", params, page_size, max_pages)\n",
    "\n",
    "def fills_by_order_id(fills: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Group fills by order_id: { order_id: [fill, ...] }\n",
    "    \"\"\"\n",
    "    grouped: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for f in fills:\n",
    "        oid = str(f.get(\"order_id\"))\n",
    "        grouped.setdefault(oid, []).append(f)\n",
    "    # Sort each list by created_at if present\n",
    "    for oid in grouped:\n",
    "        grouped[oid].sort(key=lambda x: x.get(\"created_at\", \"\"))\n",
    "    return grouped\n",
    "\n",
    "# ---------- Convenience: reconcile orders ⇄ fills ----------\n",
    "\n",
    "def join_orders_fills(orders: List[Dict[str, Any]], fills: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Returns a list of per-order summaries including weighted avg fill price, total filled size, total fees.\n",
    "    \"\"\"\n",
    "    by_order = fills_by_order_id(fills)\n",
    "    out: List[Dict[str, Any]] = []\n",
    "\n",
    "    for o in orders:\n",
    "        oid = str(o.get(\"id\"))\n",
    "        fs = by_order.get(oid, [])\n",
    "        total_qty = 0.0\n",
    "        notional = 0.0\n",
    "        fee_total = 0.0\n",
    "\n",
    "        for f in fs:\n",
    "            # prices/sizes may be strings; coerce safely\n",
    "            price = float(f.get(\"price\") or 0)\n",
    "            size  = float(f.get(\"size\") or 0)\n",
    "            fee   = float(f.get(\"fee\") or 0)\n",
    "            notional += price * size\n",
    "            total_qty += size\n",
    "            fee_total += fee\n",
    "\n",
    "        avg_price = (notional / total_qty) if total_qty else None\n",
    "\n",
    "        out.append({\n",
    "            \"order_id\": oid,\n",
    "            \"state\": o.get(\"state\"),\n",
    "            \"product_symbol\": o.get(\"product_symbol\") or (o.get(\"product\", {}) or {}).get(\"symbol\"),\n",
    "            \"side\": o.get(\"side\"),\n",
    "            \"submitted_size\": o.get(\"size\"),\n",
    "            \"filled_size\": total_qty,\n",
    "            \"avg_fill_price\": avg_price,\n",
    "            \"fee_total\": fee_total,\n",
    "            \"created_at\": o.get(\"created_at\"),\n",
    "            \"updated_at\": o.get(\"updated_at\"),\n",
    "            \"order_type\": o.get(\"order_type\"),\n",
    "            \"reduce_only\": o.get(\"reduce_only\"),\n",
    "            \"time_in_force\": o.get(\"time_in_force\"),\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "# ---------- Example run ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set env first:\n",
    "    #   export DELTA_API_KEY=...\n",
    "    #   export DELTA_API_SECRET=...\n",
    "    # Optionally: filter specific products (e.g., SOLUSD = 14823)\n",
    "    try:\n",
    "        orders = get_all_orders(states=None, product_ids=None)\n",
    "        fills  = get_all_fills(product_ids=None)\n",
    "\n",
    "        print(f\"Orders: {len(orders)} | Fills: {len(fills)}\")\n",
    "\n",
    "        joined = join_orders_fills(orders, fills)\n",
    "        # Print first 3 summaries nicely\n",
    "        for row in joined[:3]:\n",
    "            print(row)\n",
    "\n",
    "    except DeltaIndiaError as e:\n",
    "        print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc10a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ist = \"2025-08-20T00:00:00+05:30\"\n",
    "end_ist   = \"2025-08-25T23:59:59+05:30\"\n",
    "orders_ist_window = get_all_orders_in_range(start=start_ist, end=end_ist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c40395c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orders_ist_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59366e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828 [{'bracket_trail_amount': None, 'stop_order_type': None, 'meta_data': {'bracket_stop_trigger_method': 'mark_price', 'ip': '103.111.180.174', 'otc': False, 'source': 'desktop'}, 'bracket_take_profit_limit_price': None, 'order_type': 'limit_order', 'product_id': 14823, 'product': {'contract_type': 'perpetual_futures', 'contract_unit_currency': 'SOL', 'contract_value': '1', 'id': 14823, 'notional_type': 'vanilla', 'quoting_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'settling_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'spot_index': {'symbol': '.DESOLUSD'}, 'symbol': 'SOLUSD', 'tick_size': '0.0001', 'underlying_asset': {'minimum_precision': 4, 'precision': 8, 'symbol': 'SOL'}}, 'time_in_force': 'gtc', 'state': 'cancelled', 'trail_amount': None, 'average_fill_price': None, 'id': 878398215, 'close_on_trigger': 'false', 'stop_price': None, 'paid_commission': '0', 'side': 'buy', 'user_id': 93020796, 'limit_price': '187.5414', 'client_order_id': None, 'bracket_stop_loss_limit_price': None, 'cancellation_reason': 'cancelled_by_user', 'quote_size': None, 'bracket_take_profit_price': None, 'mmp': 'disabled', 'unfilled_size': 5, 'commission': '0', 'updated_at': '2025-08-26T08:40:22.017796Z', 'reduce_only': False, 'product_symbol': 'SOLUSD', 'stop_trigger_method': None, 'size': 5, 'bracket_order': None, 'bracket_stop_loss_price': '187.4775', 'created_at': '2025-08-26T08:40:13.592281Z'}, {'bracket_trail_amount': None, 'stop_order_type': 'stop_loss_order', 'meta_data': {'avg_exit_price': '188.285', 'cashflow': '-3.3345', 'edit_timestamp': '2025-08-25 20:21:47.987021Z', 'entry_price': '188.95190000', 'exit_price_with_size': [{'price': '188.28500000', 'size': '5'}], 'ip': None, 'otc': False, 'pnl': '-3.3345', 'roe': '-28.23575735412028140495014869', 'source': 'web'}, 'bracket_take_profit_limit_price': None, 'order_type': 'market_order', 'product_id': 14823, 'product': {'contract_type': 'perpetual_futures', 'contract_unit_currency': 'SOL', 'contract_value': '1', 'id': 14823, 'notional_type': 'vanilla', 'quoting_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'settling_asset': {'minimum_precision': 2, 'precision': 8, 'symbol': 'USD'}, 'spot_index': {'symbol': '.DESOLUSD'}, 'symbol': 'SOLUSD', 'tick_size': '0.0001', 'underlying_asset': {'minimum_precision': 4, 'precision': 8, 'symbol': 'SOL'}}, 'time_in_force': 'gtc', 'state': 'closed', 'trail_amount': None, 'average_fill_price': '188.285', 'id': 875971359, 'close_on_trigger': 'false', 'stop_price': '188.3276', 'paid_commission': '0', 'side': 'sell', 'user_id': 93020796, 'limit_price': '169.745', 'client_order_id': None, 'bracket_stop_loss_limit_price': None, 'cancellation_reason': None, 'quote_size': None, 'bracket_take_profit_price': None, 'mmp': 'disabled', 'unfilled_size': 0, 'commission': '0', 'updated_at': '2025-08-25T20:32:41.954658Z', 'reduce_only': True, 'product_symbol': 'SOLUSD', 'stop_trigger_method': 'mark_price', 'size': 5, 'bracket_order': True, 'bracket_stop_loss_price': None, 'created_at': '2025-08-25T20:21:32.842227Z'}]\n"
     ]
    }
   ],
   "source": [
    "orders = get_all_orders(states=None)                   # everything\n",
    "open_orders = get_all_orders(states=[\"open\",\"pending\"])\n",
    "print(len(orders), orders[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6102c427",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://api.india.delta.exchange/v2/fills?page_size=200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_fills \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_fills\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                          \u001b[38;5;66;03m# every fill\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sol_fills \u001b[38;5;241m=\u001b[39m get_all_fills(product_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m14823\u001b[39m])       \u001b[38;5;66;03m# SOLUSD only\u001b[39;00m\n\u001b[1;32m      3\u001b[0m by_order \u001b[38;5;241m=\u001b[39m fills_by_order_id(sol_fills)\n",
      "Cell \u001b[0;32mIn[30], line 27\u001b[0m, in \u001b[0;36mget_all_fills\u001b[0;34m(product_ids, page_size, max_pages)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m product_ids:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# API accepts comma-separated product ids\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m product_ids)\n\u001b[0;32m---> 27\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v2/fills\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m result \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m     29\u001b[0m fills\u001b[38;5;241m.\u001b[39mextend(result)\n",
      "Cell \u001b[0;32mIn[23], line 38\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(method, path, params, body)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/finai/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://api.india.delta.exchange/v2/fills?page_size=200"
     ]
    }
   ],
   "source": [
    "\n",
    "all_fills = get_all_fills()                          # every fill\n",
    "sol_fills = get_all_fills(product_ids=[14823])       # SOLUSD only\n",
    "by_order = fills_by_order_id(sol_fills)\n",
    "print(len(all_fills), list(by_order)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1df5e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 105 trades\n",
      "{'symbol': 'SOLUSD', 'direction': 'short', 'size': 3.0, 'avg_entry': 183.03599999999997, 'avg_exit': 181.73566666666667, 'total_fee': 0.0, 'realized_pnl': 3.9010000000000105, 'opened_at': '2025-08-18T13:23:41.777908Z', 'closed_at': '2025-08-18T15:50:50.115058Z', 'legs': [{'label': 'sl', 'order_id': '842728902', 'filled_size': 1.0, 'avg_price': 183.007, 'fee': 0.0, 'leg_pnl': 0.028999999999996362}, {'label': 'tp1', 'order_id': '842837963', 'filled_size': 2.0, 'avg_price': 181.1, 'fee': 0.0, 'leg_pnl': 3.872000000000014}]}\n",
      "{'symbol': 'SOLUSD', 'direction': 'long', 'size': 3.0, 'avg_entry': 182.037, 'avg_exit': 182.40600000000003, 'total_fee': 0.0, 'realized_pnl': 1.1069999999999993, 'opened_at': '2025-08-19T12:13:23.455545Z', 'closed_at': '2025-08-19T12:27:47.067015Z', 'legs': [{'label': 'tp1', 'order_id': '846889757', 'filled_size': 3.0, 'avg_price': 182.40600000000003, 'fee': 0.0, 'leg_pnl': 1.1069999999999993}]}\n",
      "{'symbol': 'SOLUSD', 'direction': 'short', 'size': 3.0, 'avg_entry': 182.586, 'avg_exit': 183.13700000000003, 'total_fee': 0.0, 'realized_pnl': -1.6529999999999632, 'opened_at': '2025-08-19T13:25:47.178477Z', 'closed_at': '2025-08-19T13:30:41.762774Z', 'legs': [{'label': 'sl', 'order_id': '847049673', 'filled_size': 3.0, 'avg_price': 183.13700000000003, 'fee': 0.0, 'leg_pnl': -1.6529999999999632}]}\n",
      "{'symbol': 'SOLUSD', 'direction': 'long', 'size': 3.0, 'avg_entry': 181.947, 'avg_exit': 182.6626666666667, 'total_fee': 0.0, 'realized_pnl': 2.14700000000002, 'opened_at': '2025-08-19T13:32:46.623297Z', 'closed_at': '2025-08-19T14:08:07.368855Z', 'legs': [{'label': 'tp1', 'order_id': '847271283', 'filled_size': 2.0, 'avg_price': 182.686, 'fee': 0.0, 'leg_pnl': 1.4780000000000086}, {'label': 'tp2', 'order_id': '847323763', 'filled_size': 1.0, 'avg_price': 182.616, 'fee': 0.0, 'leg_pnl': 0.6690000000000111}]}\n",
      "{'symbol': 'SOLUSD', 'direction': 'short', 'size': 3.0, 'avg_entry': 182.606, 'avg_exit': 179.10706666666667, 'total_fee': 0.0, 'realized_pnl': 10.496799999999979, 'opened_at': '2025-08-19T14:08:29.045471Z', 'closed_at': '2025-08-19T18:51:05.906679Z', 'legs': [{'label': 'tp1', 'order_id': '847378348', 'filled_size': 2.0, 'avg_price': 180.6338, 'fee': 0.0, 'leg_pnl': 3.9443999999999733}, {'label': 'tp2', 'order_id': '847472451', 'filled_size': 1.0, 'avg_price': 176.0536, 'fee': 0.0, 'leg_pnl': 6.552400000000006}]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "delta_trades.py\n",
    "\n",
    "Delta Exchange India client + trade assembler.\n",
    "\n",
    "What you get:\n",
    "- Authenticated REST client (orders + fills) with HMAC signing.\n",
    "- Dataclasses for Order, Fill, and Trade.\n",
    "- A robust assembler that collapses multiple exit legs (TP1/TP2/SL/manual)\n",
    "  into a single Trade (flat-to-flat), with FIFO PnL and useful summaries.\n",
    "\n",
    "Requirements:\n",
    "- Python 3.10+\n",
    "- requests\n",
    "\n",
    "Environment:\n",
    "    export DELTA_API_KEY=...\n",
    "    export DELTA_API_SECRET=...\n",
    "\n",
    "Notes:\n",
    "- Base URL is India: https://api.india.delta.exchange\n",
    "- Pagination uses cursor meta.after\n",
    "- We infer \"TP\" vs \"SL\" legs:\n",
    "    * If order.stop_order_type is set → 'sl'\n",
    "    * Else reduce_only True and price favorable vs. avg entry → 'tp'\n",
    "    * Else → 'manual'\n",
    "- Position cycles are detected per symbol by walking orders in time:\n",
    "    We treat non-reduce-only orders as entries/scale-ins, and reduce-only\n",
    "    orders as exits/scale-outs. A Trade is complete when position returns to 0.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, time, hmac, hashlib, json, math, requests\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Iterable, Dict, Any, List, Tuple\n",
    "from urllib.parse import urlencode\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Low-level HTTP Client\n",
    "# =========================\n",
    "\n",
    "class DeltaIndiaError(Exception):\n",
    "    \"\"\"Raised for transport or API errors from Delta Exchange India.\"\"\"\n",
    "\n",
    "\n",
    "class DeltaIndiaClient:\n",
    "    \"\"\"\n",
    "    Minimal authenticated client for Delta Exchange India private REST APIs.\n",
    "\n",
    "    Methods:\n",
    "        get_orders(...)      -> List[dict]\n",
    "        get_orders_history(...) -> List[dict]\n",
    "        get_fills(...)       -> List[dict]\n",
    "        get_all_orders(...)  -> List[dict]\n",
    "        get_all_fills(...)   -> List[dict]\n",
    "\n",
    "    Usage:\n",
    "        client = DeltaIndiaClient()\n",
    "        orders = client.get_all_orders()\n",
    "        fills  = client.get_all_fills()\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_URL = \"https://api.india.delta.exchange\"\n",
    "    USER_AGENT = \"delta-india-python/1.0\"\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None, api_secret: Optional[str] = None):\n",
    "        self.api_key = api_key or os.getenv(\"DELTA_API_KEY\")\n",
    "        self.api_secret = api_secret or os.getenv(\"DELTA_API_SECRET\")\n",
    "        if not self.api_key or not self.api_secret:\n",
    "            raise DeltaIndiaError(\"Missing DELTA_API_KEY / DELTA_API_SECRET environment variables or constructor args.\")\n",
    "\n",
    "    # ---------- signing / request ----------\n",
    "\n",
    "    @staticmethod\n",
    "    def _now_ts() -> str:\n",
    "        # Delta expects seconds (int) as string\n",
    "        return str(int(time.time()))\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_query(params: Optional[dict]) -> str:\n",
    "        if not params:\n",
    "            return \"\"\n",
    "        return \"?\" + urlencode(params, doseq=True)\n",
    "\n",
    "    def _sign(self, method: str, path: str, params: Optional[dict] = None, body: Optional[dict] = None) -> Tuple[dict, str]:\n",
    "        \"\"\"\n",
    "        HMAC_SHA256(secret, method + timestamp + path + query + body_json)\n",
    "        - query: MUST include leading '?' if present\n",
    "        - body_json: minified JSON string (no spaces)\n",
    "        \"\"\"\n",
    "        ts = self._now_ts()\n",
    "        q = self._build_query(params)\n",
    "        b = json.dumps(body, separators=(\",\", \":\")) if body else \"\"\n",
    "        prehash = f\"{method.upper()}{ts}{path}{q}{b}\"\n",
    "        sig = hmac.new(self.api_secret.encode(), prehash.encode(), hashlib.sha256).hexdigest()\n",
    "        headers = {\n",
    "            \"api-key\": self.api_key,\n",
    "            \"signature\": sig,\n",
    "            \"timestamp\": ts,\n",
    "            \"User-Agent\": self.USER_AGENT,\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        return headers, b\n",
    "\n",
    "    def _request(self, method: str, path: str, params: Optional[dict] = None, body: Optional[dict] = None) -> dict:\n",
    "        headers, body_json = self._sign(method, path, params, body)\n",
    "        url = f\"{self.BASE_URL}{path}\"\n",
    "        try:\n",
    "            if method.upper() == \"GET\":\n",
    "                r = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "            elif method.upper() == \"POST\":\n",
    "                r = requests.post(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "            elif method.upper() == \"DELETE\":\n",
    "                r = requests.delete(url, params=params, data=body_json, headers=headers, timeout=30)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported method: {method}\")\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if isinstance(data, dict) and data.get(\"success\") is False:\n",
    "                raise DeltaIndiaError(f\"Delta API error: {data}\")\n",
    "            return data\n",
    "        except requests.HTTPError as e:\n",
    "            msg = e.response.text if e.response is not None else str(e)\n",
    "            code = e.response.status_code if e.response is not None else \"?\"\n",
    "            raise DeltaIndiaError(f\"HTTPError {code}: {msg}\") from e\n",
    "        except requests.RequestException as e:\n",
    "            raise DeltaIndiaError(f\"Network error: {e}\") from e\n",
    "\n",
    "    # ---------- pagination helper ----------\n",
    "\n",
    "    def _page_through(self, path: str, params: Optional[dict] = None, page_size: int = 200, max_pages: Optional[int] = None) -> List[dict]:\n",
    "        params = dict(params or {})\n",
    "        out: List[dict] = []\n",
    "        after = None\n",
    "        pages = 0\n",
    "        while True:\n",
    "            req_params = dict(params)\n",
    "            req_params[\"page_size\"] = page_size\n",
    "            if after:\n",
    "                req_params[\"after\"] = after\n",
    "            data = self._request(\"GET\", path, req_params)\n",
    "            result = data.get(\"result\", [])\n",
    "            out.extend(result)\n",
    "            meta = data.get(\"meta\") or {}\n",
    "            after = meta.get(\"after\")\n",
    "            pages += 1\n",
    "            if not after:\n",
    "                break\n",
    "            if max_pages is not None and pages >= max_pages:\n",
    "                break\n",
    "        return out\n",
    "\n",
    "    # ---------- public methods ----------\n",
    "\n",
    "    def get_orders(self, *, states: Optional[Iterable[str]] = None, product_ids: Optional[Iterable[int]] = None,\n",
    "                   page_size: int = 200, max_pages: Optional[int] = None) -> List[dict]:\n",
    "        params = {}\n",
    "        if states:\n",
    "            params[\"states\"] = \",\".join(states)\n",
    "        if product_ids:\n",
    "            params[\"product_ids\"] = \",\".join(str(p) for p in product_ids)\n",
    "        return self._page_through(\"/v2/orders\", params, page_size, max_pages)\n",
    "\n",
    "    def get_orders_history(self, *, states: Optional[Iterable[str]] = None, product_ids: Optional[Iterable[int]] = None,\n",
    "                           page_size: int = 200, max_pages: Optional[int] = None) -> List[dict]:\n",
    "        params = {}\n",
    "        if states:\n",
    "            params[\"states\"] = \",\".join(states)\n",
    "        if product_ids:\n",
    "            params[\"product_ids\"] = \",\".join(str(p) for p in product_ids)\n",
    "        return self._page_through(\"/v2/orders/history\", params, page_size, max_pages)\n",
    "\n",
    "    def get_fills(self, *, product_ids: Optional[Iterable[int]] = None, page_size: int = 200,\n",
    "                  max_pages: Optional[int] = None) -> List[dict]:\n",
    "        params = {}\n",
    "        if product_ids:\n",
    "            params[\"product_ids\"] = \",\".join(str(p) for p in product_ids)\n",
    "        return self._page_through(\"/v2/fills\", params, page_size, max_pages)\n",
    "\n",
    "    # convenience\n",
    "    def get_all_orders(self, **kwargs) -> List[dict]:\n",
    "        return self.get_orders(**kwargs) + self.get_orders_history(**kwargs)\n",
    "\n",
    "    def get_all_fills(self, **kwargs) -> List[dict]:\n",
    "        return self.get_fills(**kwargs)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Domain Records\n",
    "# =========================\n",
    "\n",
    "def _to_float(x: Any) -> float:\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def _ts(s: Optional[str]) -> float:\n",
    "    \"\"\"Parse ISO8601 to timestamp (seconds).\"\"\"\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    try:\n",
    "        return datetime.fromisoformat(s.replace(\"Z\", \"+00:00\")).timestamp()\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "@dataclass\n",
    "class Fill:\n",
    "    order_id: str\n",
    "    symbol: str\n",
    "    side: str              # 'buy' or 'sell'\n",
    "    price: float\n",
    "    size: float\n",
    "    fee: float\n",
    "    created_at: str\n",
    "\n",
    "    @staticmethod\n",
    "    def from_api(d: dict) -> \"Fill\":\n",
    "        return Fill(\n",
    "            order_id=str(d.get(\"order_id\")),\n",
    "            symbol=d.get(\"product_symbol\") or (d.get(\"product\", {}) or {}).get(\"symbol\") or \"\",\n",
    "            side=(d.get(\"side\") or \"\").lower(),\n",
    "            price=_to_float(d.get(\"price\")),\n",
    "            size=_to_float(d.get(\"size\")),\n",
    "            fee=_to_float(d.get(\"fee\")),\n",
    "            created_at=d.get(\"created_at\") or \"\",\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class Order:\n",
    "    id: str\n",
    "    symbol: str\n",
    "    side: str              # 'buy' / 'sell'\n",
    "    size: float\n",
    "    state: str\n",
    "    reduce_only: bool\n",
    "    order_type: str\n",
    "    created_at: str\n",
    "    updated_at: str\n",
    "    stop_order_type: Optional[str] = None\n",
    "    client_order_id: Optional[str] = None\n",
    "    bracket_order: bool = False\n",
    "    meta_data: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_api(d: dict) -> \"Order\":\n",
    "        return Order(\n",
    "            id=str(d.get(\"id\")),\n",
    "            symbol=d.get(\"product_symbol\") or (d.get(\"product\", {}) or {}).get(\"symbol\") or \"\",\n",
    "            side=(d.get(\"side\") or \"\").lower(),\n",
    "            size=_to_float(d.get(\"size\")),\n",
    "            state=(d.get(\"state\") or \"\").lower(),\n",
    "            reduce_only=bool(d.get(\"reduce_only\")),\n",
    "            order_type=d.get(\"order_type\") or \"\",\n",
    "            created_at=d.get(\"created_at\") or \"\",\n",
    "            updated_at=d.get(\"updated_at\") or \"\",\n",
    "            stop_order_type=d.get(\"stop_order_type\"),\n",
    "            client_order_id=d.get(\"client_order_id\"),\n",
    "            bracket_order=bool(d.get(\"bracket_order\")),\n",
    "            meta_data=d.get(\"meta_data\") or {},\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class TradeLeg:\n",
    "    \"\"\"One exit leg in a trade (TP/SL/manual) with its fills aggregated.\"\"\"\n",
    "    label: str             # 'tp1', 'tp2', ..., or 'sl', or 'manual'\n",
    "    order: Order\n",
    "    fills: List[Fill]\n",
    "    filled_size: float\n",
    "    avg_price: float\n",
    "    fee: float\n",
    "    realized_pnl: float    # pnl contributed by this leg (USD)\n",
    "\n",
    "@dataclass\n",
    "class Trade:\n",
    "    \"\"\"\n",
    "    A flat-to-flat cycle per symbol (multi-entry + multi-exit supported).\n",
    "    We track FIFO across fills to compute realized PnL.\n",
    "\n",
    "    Attributes:\n",
    "        symbol: product symbol (e.g., 'SOLUSD')\n",
    "        direction: 'long' or 'short'\n",
    "        entry_orders: list of non-reduce-only orders that opened/added\n",
    "        entry_fills: all entry fills (buy for long, sell for short)\n",
    "        exit_legs: list of TradeLegs in time sequence\n",
    "        size: maximum absolute position size during the cycle\n",
    "        avg_entry: weighted average entry across entry_fills\n",
    "        avg_exit: weighted average of all exit fills (None if still open)\n",
    "        total_fee: sum of fees across all fills in the trade\n",
    "        realized_pnl: realized PnL for the whole cycle (USD)\n",
    "        opened_at / closed_at: ISO times\n",
    "    \"\"\"\n",
    "    symbol: str\n",
    "    direction: str\n",
    "    entry_orders: List[Order] = field(default_factory=list)\n",
    "    entry_fills: List[Fill] = field(default_factory=list)\n",
    "    exit_legs: List[TradeLeg] = field(default_factory=list)\n",
    "    size: float = 0.0\n",
    "    avg_entry: Optional[float] = None\n",
    "    avg_exit: Optional[float] = None\n",
    "    total_fee: float = 0.0\n",
    "    realized_pnl: float = 0.0\n",
    "    opened_at: Optional[str] = None\n",
    "    closed_at: Optional[str] = None\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"symbol\": self.symbol,\n",
    "            \"direction\": self.direction,\n",
    "            \"size\": self.size,\n",
    "            \"avg_entry\": self.avg_entry,\n",
    "            \"avg_exit\": self.avg_exit,\n",
    "            \"total_fee\": self.total_fee,\n",
    "            \"realized_pnl\": self.realized_pnl,\n",
    "            \"opened_at\": self.opened_at,\n",
    "            \"closed_at\": self.closed_at,\n",
    "            \"legs\": [\n",
    "                {\n",
    "                    \"label\": leg.label,\n",
    "                    \"order_id\": leg.order.id,\n",
    "                    \"filled_size\": leg.filled_size,\n",
    "                    \"avg_price\": leg.avg_price,\n",
    "                    \"fee\": leg.fee,\n",
    "                    \"leg_pnl\": leg.realized_pnl,\n",
    "                }\n",
    "                for leg in self.exit_legs\n",
    "            ],\n",
    "        }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Assembler\n",
    "# =========================\n",
    "\n",
    "class TradeAssembler:\n",
    "    \"\"\"\n",
    "    Builds Trade objects from raw orders + fills.\n",
    "\n",
    "    How it works (per symbol):\n",
    "      1) Sort all orders by created_at ascending, attach their fills (by order_id).\n",
    "      2) Maintain a running 'position queue' of entry fills (FIFO).\n",
    "      3) Non-reduce-only orders add to the queue (entries/scale-ins).\n",
    "      4) Reduce-only orders drain the queue (exits/scale-outs):\n",
    "         - Each exit order becomes a leg (tp1/tp2/... or sl/manual).\n",
    "         - FIFO matching computes PnL for that leg.\n",
    "      5) When the queue returns to zero size → close the Trade (flat).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, orders: List[dict], fills: List[dict]):\n",
    "        # Normalize to dataclasses\n",
    "        self.orders: List[Order] = [Order.from_api(o) for o in orders]\n",
    "        self.fills: List[Fill] = [Fill.from_api(f) for f in fills]\n",
    "        # Group fills by order_id\n",
    "        self.fills_by_order: Dict[str, List[Fill]] = {}\n",
    "        for f in self.fills:\n",
    "            self.fills_by_order.setdefault(f.order_id, []).append(f)\n",
    "        # Sort fills in time within each order\n",
    "        for oid in self.fills_by_order:\n",
    "            self.fills_by_order[oid].sort(key=lambda x: _ts(x.created_at))\n",
    "\n",
    "    def assemble(self) -> List[Trade]:\n",
    "        trades: List[Trade] = []\n",
    "        # group by symbol\n",
    "        by_symbol: Dict[str, List[Order]] = {}\n",
    "        for o in self.orders:\n",
    "            by_symbol.setdefault(o.symbol, []).append(o)\n",
    "        # process each symbol independently\n",
    "        for symbol, olist in by_symbol.items():\n",
    "            olist.sort(key=lambda o: _ts(o.created_at))\n",
    "            trades.extend(self._assemble_symbol(symbol, olist))\n",
    "        return trades\n",
    "\n",
    "    # ---------- per-symbol assembly ----------\n",
    "\n",
    "    def _assemble_symbol(self, symbol: str, orders: List[Order]) -> List[Trade]:\n",
    "        trades: List[Trade] = []\n",
    "\n",
    "        # position FIFO queue: list of entry fills with remaining size to match\n",
    "        # For LONG: entries are BUY fills; exits must be SELL reduce_only\n",
    "        # For SHORT: entries are SELL fills; exits must be BUY reduce_only\n",
    "        pos_queue: List[Fill] = []\n",
    "        current: Optional[Trade] = None\n",
    "        tp_counter = 0\n",
    "\n",
    "        def direction_from_order(o: Order) -> Optional[str]:\n",
    "            if o.reduce_only:\n",
    "                return None\n",
    "            if o.side == \"buy\":\n",
    "                return \"long\"\n",
    "            if o.side == \"sell\":\n",
    "                return \"short\"\n",
    "            return None\n",
    "\n",
    "        def infer_leg_label(o: Order, entry_avg: Optional[float]) -> str:\n",
    "            # SL signal from stop_order_type\n",
    "            if o.stop_order_type:\n",
    "                return \"sl\"\n",
    "            # Heuristic TP if price is favorable vs entry_avg\n",
    "            fs = self.fills_by_order.get(o.id, [])\n",
    "            if not fs or entry_avg is None:\n",
    "                return \"manual\"\n",
    "            avg_exit = _weighted_avg([(f.price, f.size) for f in fs])\n",
    "            if avg_exit is None:\n",
    "                return \"manual\"\n",
    "            if current and current.direction == \"long\":\n",
    "                return \"tp\" if avg_exit > entry_avg else \"manual\"\n",
    "            if current and current.direction == \"short\":\n",
    "                return \"tp\" if avg_exit < entry_avg else \"manual\"\n",
    "            return \"manual\"\n",
    "\n",
    "        for o in orders:\n",
    "            ofills = self.fills_by_order.get(o.id, [])\n",
    "\n",
    "            # 1) ENTRY / SCALE-IN (non-reduce-only)\n",
    "            if not o.reduce_only:\n",
    "                dirn = direction_from_order(o)\n",
    "                if dirn:\n",
    "                    # start new trade if none active\n",
    "                    if current is None:\n",
    "                        current = Trade(symbol=symbol, direction=dirn)\n",
    "                        tp_counter = 0\n",
    "                    # If direction flips mid-cycle (edge), close previous (force) and start new\n",
    "                    elif current.direction != dirn and _sum_size(pos_queue) != 0:\n",
    "                        # Forced close with no explicit reduce-only exits: mark as manual close at last fill price\n",
    "                        _finalize_trade_without_exits(current, pos_queue)\n",
    "                        trades.append(current)\n",
    "                        current = Trade(symbol=symbol, direction=dirn)\n",
    "                        tp_counter = 0\n",
    "\n",
    "                    # push entry fills\n",
    "                    for f in ofills:\n",
    "                        if _is_entry_fill(current.direction, f.side):\n",
    "                            pos_queue.append(f)\n",
    "                            current.entry_fills.append(f)\n",
    "                            current.size = max(current.size, abs(_sum_size(pos_queue)))\n",
    "                            current.total_fee += f.fee\n",
    "                            if current.opened_at is None or _ts(f.created_at) < _ts(current.opened_at):\n",
    "                                current.opened_at = f.created_at\n",
    "                    current.entry_orders.append(o)\n",
    "                    current.avg_entry = _weighted_avg([(f.price, f.size) for f in current.entry_fills])\n",
    "\n",
    "            # 2) EXIT / SCALE-OUT (reduce-only)\n",
    "            else:\n",
    "                if current is None:\n",
    "                    # Reduce-only but no active trade in assembler; skip or start a synthetic short/long?\n",
    "                    # We'll treat as manual isolated leg (open & close immediately) by creating a tiny trade.\n",
    "                    synthetic = _synthetic_trade_from_reduce_only(symbol, o, ofills)\n",
    "                    if synthetic:\n",
    "                        trades.append(synthetic)\n",
    "                    continue\n",
    "\n",
    "                # Match fills FIFO and compute PnL contribution\n",
    "                exit_size = sum(f.size for f in ofills if _is_exit_fill(current.direction, f.side))\n",
    "                if exit_size <= 0:\n",
    "                    continue\n",
    "\n",
    "                # Leg label\n",
    "                leg_type = infer_leg_label(o, current.avg_entry)\n",
    "                if leg_type == \"tp\":\n",
    "                    tp_counter += 1\n",
    "                    leg_label = f\"tp{tp_counter}\"\n",
    "                else:\n",
    "                    leg_label = leg_type  # 'sl' or 'manual'\n",
    "\n",
    "                realized_pnl, fee_sum, matched_fills, exit_avg = _fifo_match_pnl(\n",
    "                    direction=current.direction,\n",
    "                    pos_queue=pos_queue,\n",
    "                    exit_fills=[f for f in ofills if _is_exit_fill(current.direction, f.side)]\n",
    "                )\n",
    "\n",
    "                # record leg\n",
    "                leg = TradeLeg(\n",
    "                    label=leg_label,\n",
    "                    order=o,\n",
    "                    fills=matched_fills,\n",
    "                    filled_size=sum(f.size for f in matched_fills),\n",
    "                    avg_price=exit_avg or 0.0,\n",
    "                    fee=fee_sum,\n",
    "                    realized_pnl=realized_pnl\n",
    "                )\n",
    "                current.exit_legs.append(leg)\n",
    "                current.total_fee += fee_sum\n",
    "                current.realized_pnl += realized_pnl\n",
    "\n",
    "                # If position fully closed → finalize trade\n",
    "                if _sum_size(pos_queue) == 0:\n",
    "                    current.avg_exit = _weighted_avg([\n",
    "                        (leg.avg_price, leg.filled_size) for leg in current.exit_legs if leg.filled_size > 0\n",
    "                    ])\n",
    "                    # closed_at = last exit fill time\n",
    "                    last_exit_ts, last_exit_iso = 0.0, None\n",
    "                    for L in current.exit_legs:\n",
    "                        for f in L.fills:\n",
    "                            ts = _ts(f.created_at)\n",
    "                            if ts >= last_exit_ts:\n",
    "                                last_exit_ts, last_exit_iso = ts, f.created_at\n",
    "                    current.closed_at = last_exit_iso\n",
    "                    trades.append(current)\n",
    "                    current = None\n",
    "                    tp_counter = 0\n",
    "\n",
    "        # If leftover open position -> leave as open trade (no close legs)\n",
    "        if current and _sum_size(pos_queue) > 0:\n",
    "            # keep as open; avg_exit None\n",
    "            trades.append(current)\n",
    "\n",
    "        return trades\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def _sum_size(fills: List[Fill]) -> float:\n",
    "    return sum(f.size for f in fills)\n",
    "\n",
    "def _weighted_avg(pairs: List[Tuple[float, float]]) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    pairs = [(price, size), ...]\n",
    "    \"\"\"\n",
    "    num = sum(p * s for p, s in pairs)\n",
    "    den = sum(s for _, s in pairs)\n",
    "    return (num / den) if den > 0 else None\n",
    "\n",
    "def _is_entry_fill(direction: str, fill_side: str) -> bool:\n",
    "    return (direction == \"long\" and fill_side == \"buy\") or (direction == \"short\" and fill_side == \"sell\")\n",
    "\n",
    "def _is_exit_fill(direction: str, fill_side: str) -> bool:\n",
    "    return (direction == \"long\" and fill_side == \"sell\") or (direction == \"short\" and fill_side == \"buy\")\n",
    "\n",
    "def _fifo_match_pnl(direction: str, pos_queue: List[Fill], exit_fills: List[Fill]) -> Tuple[float, float, List[Fill], Optional[float]]:\n",
    "    \"\"\"\n",
    "    Match exit fills against pos_queue (entry fills) FIFO to compute realized PnL.\n",
    "\n",
    "    Returns:\n",
    "        realized_pnl (USD), fee_sum, matched_exit_fills (possibly split), exit_avg_price\n",
    "    \"\"\"\n",
    "    realized = 0.0\n",
    "    fee_sum = 0.0\n",
    "    matched: List[Fill] = []\n",
    "    weighted_pairs: List[Tuple[float, float]] = []\n",
    "\n",
    "    # Clone queue sizes we can mutate\n",
    "    i = 0\n",
    "    for ex in exit_fills:\n",
    "        remaining = ex.size\n",
    "        fee_sum += ex.fee\n",
    "        while remaining > 1e-12 and i < len(pos_queue):\n",
    "            en = pos_queue[i]\n",
    "            take = min(remaining, en.size)\n",
    "            # Effective prices\n",
    "            en_px, ex_px = en.price, ex.price\n",
    "            # direction → sign of pnl\n",
    "            if direction == \"long\":\n",
    "                pnl = (ex_px - en_px) * take\n",
    "            else:\n",
    "                pnl = (en_px - ex_px) * take\n",
    "            realized += pnl\n",
    "            weighted_pairs.append((ex_px, take))\n",
    "            matched.append(Fill(\n",
    "                order_id=ex.order_id, symbol=ex.symbol, side=ex.side,\n",
    "                price=ex_px, size=take, fee=0.0, created_at=ex.created_at\n",
    "            ))\n",
    "            # reduce from entry lot\n",
    "            en.size -= take\n",
    "            remaining -= take\n",
    "            if en.size <= 1e-12:\n",
    "                i += 1  # consume entry lot completely\n",
    "\n",
    "    # Remove fully consumed entry lots from queue head\n",
    "    del pos_queue[:i]\n",
    "    exit_avg = _weighted_avg(weighted_pairs)\n",
    "    return realized, fee_sum, matched, exit_avg\n",
    "\n",
    "def _finalize_trade_without_exits(trade: Trade, pos_queue: List[Fill]) -> None:\n",
    "    \"\"\"\n",
    "    Edge-case helper if direction flips without explicit reduce-only legs.\n",
    "    We mark everything closed at the last entry fill price (realized PnL = 0).\n",
    "    \"\"\"\n",
    "    if not trade.entry_fills:\n",
    "        return\n",
    "    trade.avg_entry = _weighted_avg([(f.price, f.size) for f in trade.entry_fills])\n",
    "    trade.avg_exit = trade.avg_entry\n",
    "    trade.closed_at = max((f.created_at for f in trade.entry_fills), default=None)\n",
    "    trade.realized_pnl += 0.0\n",
    "    pos_queue.clear()\n",
    "\n",
    "def _synthetic_trade_from_reduce_only(symbol: str, o: Order, ofills: List[Fill]) -> Optional[Trade]:\n",
    "    \"\"\"\n",
    "    If we see a reduce-only order without an active trade in memory,\n",
    "    create a synthetic one-order trade (manual). Useful for data gaps.\n",
    "    \"\"\"\n",
    "    if not ofills:\n",
    "        return None\n",
    "    # Guess direction by opposite of exit side\n",
    "    # If exit side is SELL, the open direction was LONG; if BUY, it was SHORT.\n",
    "    direction = \"long\" if ofills[0].side == \"sell\" else \"short\"\n",
    "    t = Trade(symbol=symbol, direction=direction)\n",
    "    # Treat fills as both entry and exit at same price → PnL ~ 0\n",
    "    for f in ofills:\n",
    "        t.entry_fills.append(Fill(order_id=f.order_id, symbol=f.symbol, side=(\"buy\" if direction==\"long\" else \"sell\"),\n",
    "                                  price=f.price, size=f.size, fee=0.0, created_at=f.created_at))\n",
    "        t.exit_legs.append(TradeLeg(label=\"manual\", order=o, fills=[f], filled_size=f.size,\n",
    "                                    avg_price=f.price, fee=f.fee, realized_pnl=0.0))\n",
    "        t.total_fee += f.fee\n",
    "    t.size = _sum_size(t.entry_fills)\n",
    "    t.avg_entry = _weighted_avg([(f.price, f.size) for f in t.entry_fills])\n",
    "    t.avg_exit = _weighted_avg([(f.price, f.size) for f in ofills])\n",
    "    t.opened_at = min((f.created_at for f in t.entry_fills), default=None)\n",
    "    t.closed_at = max((f.created_at for f in ofills), default=None)\n",
    "    return t\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Example CLI\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = DeltaIndiaClient(api_key=API_KEY, api_secret=API_SECRET)\n",
    "    # Pull everything; you can add product_ids=[14823] for SOLUSD only\n",
    "    orders = client.get_all_orders()\n",
    "    fills = client.get_all_fills()\n",
    "\n",
    "    assembler = TradeAssembler(orders, fills)\n",
    "    trades = assembler.assemble()\n",
    "\n",
    "    print(f\"Built {len(trades)} trades\")\n",
    "    for t in trades[:5]:\n",
    "        print(t.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
